# -*- coding: utf-8 -*-
import json
import scrapy
from urllib.parse import urljoin
import subprocess

FILE_STORE='/Users/emma/Work/CrawlMalware/malware/malware/data/malware/'


class ApkpureSpider(scrapy.Spider):
    name = 'apkpure'
    allowed_domains = ['apkpure.com']
    start_urls = ['https://www.apkpure.com/cn/app']
    base_url = 'https://www.apkpure.com/cn/app?page={0}/'
    current_page = 1


    def parse(self, response):
        urls = response.xpath('//*[@class="category-template-down"]//a/@href').extract()
        urls = set(urls)
        urls = list(urls)
        for url in urls:
            url = urljoin(response.url, url)
            yield scrapy.Request(url, callback=self.parse_click)

        self.current_page += 1
        next_page = self.base_url.format(self.current_page)
        yield scrapy.Request(next_page, callback=self.parse)

    def parse_click(self, respone):
        click_url = respone.xpath('//*[@class='da']/@href').extract_first()
        name = click_url.split("/")[-2]
        json_url = urljoin("https://apkpure.com",click_url)
        meta = {
            'name': name,
            'click_url': click_url,
        }
        yield scrapy.Request(json_url, meta=meta, callback=self.getDownloadJs)

    def getDownloadJs(self, response):
        re_json = json.loads(response.text)
        try:
            download_url = re_json["url"]
            p = subprocess.Popen(["wget", download_url, "-o", FILE_STORE+'/'+response.meta.get("name")+'.apk', "--limit-rate", '50k'])
            p.wait()            
        except Exception as e:
            print(e)
